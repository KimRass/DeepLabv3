# Paper Summary
- [Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1706.05587v3.pdf)
- ***With atrous convolution, one is able to control the resolution at which feature responses are computed within DCNNs without requiring learning extra parameters.***
- Employing large value of atrous rate enlarges the model's field-of-view, enabling object encoding at multiple scales.
## Related Works
- It has been shown that global features or contextual interactions are beneficial in correctly classifying pixels for semantic segmentation. In this work, we discuss four types of Fully Convolutional Networks (FCNs) that exploit context information for semantic segmentation.
- Image pyramid:
    - The same model, typically with shared weights, is applied to multi-scale inputs. ***Feature responses from the small scale inputs encode the long-range context, while the large scale inputs preserve the small object details.*** Typical examples include [...] who transform the input image through a Laplacian pyramid, feed each scale input to a DCNN and merge the feature maps from all the scales. [...] apply multi-scale inputs sequentially from coarse-to-fine, while [...] directly resize the input for several scales and fuse the features from all the scales.
- Encoder-decoder:
    - ***This model consists of two parts: (a) the encoder where the spatial dimension of feature maps is gradually reduced and thus longer range information is more easily captured in the deeper encoder output, and (b) the decoder where object details and spatial dimension are gradually recovered.*** For example, [...] employ deconvolution to learn the upsampling of low resolution feature responses. ***U-Net adds skip connections from the encoder features to the corresponding decoder activations,*** and [...] employs a Laplacian pyramid reconstruction network.
- Context module:
    - This model contains extra modules laid out in cascade to encode long-range context. One effective method is to incorporate DenseCRF [45] (with efficient high-dimensional filtering algorithms) to DCNNs.
- Spatial pyramid pooling:
    - This model employs spatial pyramid pooling to capture context at several ranges. Spatial pyramid pooling has also been applied in object detection.
- Atrous convolution:
    - Models based on atrous convolution have been actively explored for semantic segmentation.
## Methodology
- Our proposed module consists of atrous convolution with various rates and batch normalization layers which we found important to be trained as well.
- ***We discuss an important practical issue when applying a $3 \times 3$ atrous convolution with an extremely large rate, which fails to capture long range information due to image boundary effects, effectively simply degenerating to $1 \times 1$ convolution, and propose to incorporate image-level features into the ASPP module.***
- We duplicate several copies of the original last block in ResNet [32] and arrange them in cascade, and also revisit the ASPP module [11] which contains several atrous convolutions in parallel. Note that ***our cascaded modules are applied directly on the feature maps instead of belief maps.*** For the proposed modules, we experimentally find it important to train with batch normalization [38]. To further capture global context, we propose to augment ASPP with image-level features.
### Atrous Convolution
- ***Atrous convolution also allows us to explicitly control how densely to compute feature responses in fully convolutional networks.*** Here, we denote by $output\textunderscore stride$ the ratio of input image spatial resolution to final output resolution. For the DCNNs deployed for the task of image classification, the final feature responses (before fully connected layers or global pooling) is 32 times smaller than the input image dimension, and thus $output\textunderscore stride = 32$. If one would like to double the spatial density of computed feature responses in the DCNNs (i.e., $output\textunderscore stride = 16$), the stride of last pooling or convolutional layer that decreases resolution is set to 1 to avoid signal decimation. Then, all subsequent convolutional layers are replaced with atrous convolutional layers having rate $r = 2$. This allows us to extract denser feature responses without requiring learning any extra parameters.
- Figure 3.
    - <img src="https://miro.medium.com/max/1400/1*nFJ_GqK1D3zKCRgtnRfrcw.webp">
- We duplicate several copies of the last ResNet block, denoted as "Block4" in Fig. 3, and arrange them in cascade. ***There are three ***$3 \times 3$*** convolutions in those blocks, and the last convolution contains stride ***$2$*** except the one in last block, similar to original ResNet.*** The motivation behind this model is that the introduced striding makes it easy to capture long range information in the deeper blocks. For example, the whole image feature could be summarized in the last small resolution feature map, as illustrated in Fig. 3 (a). However, we discover that the consecutive striding is harmful for semantic segmentation since detail information is decimated, and thus we apply atrous convolution with rates determined by the desired $output\textunderscore stride$ value, as shown in Fig. 3 (b) where $output\textunderscore stride = 16$. In this proposed model, we experiment with cascaded ResNet blocks up to Block7 (i.e., ***extra Block5, Block6, Block7 as replicas of Block4***), which has $output\textunderscore stride = 256$ if no atrous convolution is applied.
<!-- ### Multi-grid Method -->
<!-- - ***we adopt different atrous rates within Block4 to Block7 in the proposed model. In particular, we define as ***$\text{Multi Grid} = (r_1, r_2, r_3)$*** the unit rates for the three convolutional layers within Block4 to Block7. The final atrous rate for the convolutional layer is equal to the multiplication of the unit rate and the corresponding rate. For example, when ***$output\textunderscore stride = 16$*** and ***$\text{Multi Grid} = (1, 2, 4)$***, the three convolutions will have ***$rates = 2 \cdot (1, 2, 4) = (2, 4, 8)$*** in the Block4, respectively.*** -->
### Atrous Spatial Pyramid Pooling
- ASPP with different atrous rates effectively captures multi-scale information. However, we discover that as the sampling rate becomes larger, the number of valid filter weights (i.e., the weights that are applied to the valid feature region, instead of padded zeros) becomes smaller.
- To overcome this problem and incorporate global context information to the model, we adopt image-level features. ***Specifically, we apply global average pooling on the last feature map of the model, feed the resulting image-level features to a*** $1 \times 1$ ***convolution with 256 filters (and batch normalization), and then bilinearly upsample the feature to the desired spatial dimension. In the end, our improved ASPP consists of (a) one*** $1 \times 1$ ***convolution and three*** $3 \times 3$ ***convolutions with*** $rates = (6, 12, 18)$ ***when*** $output\textunderscore stride = 16$ ***(all with 256 filters and batch normalization), and (b) the image-level features, as shown in Fig. 5. Note that the rates are doubled when*** $output\textunderscore stride = 8$***. The resulting features from all the branches are then concatenated and pass through another 1 × 1 convolution (also with 256 filters and batch normalization) before the final 1 × 1 convolution which generates the final logits.***

## References
- [11] [Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs](https://arxiv.org/pdf/1412.7062v4.pdf)
- [32] [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf)
- [39] [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)
- [45] [Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials](https://arxiv.org/pdf/1210.5644.pdf)
